{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from Person import Person\n",
    "from utils import transform\n",
    "from utils import draw\n",
    "from utils import position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 're3-tensorflow/'\n",
      "C:\\Users\\velmisov\\Ilya\\Kyrsovaya\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tracker'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e0df453df808>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtracker\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre3_tracker\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tracker'"
     ]
    }
   ],
   "source": [
    "%cd re3-tensorflow/\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tracker import re3_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ilya\\Kyrsach\\Kyrsovaya\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ilya\\Kyrsach\\Kyrsovaya\\darkflow-master\n"
     ]
    }
   ],
   "source": [
    "% cd ./darkflow-master/\n",
    "from darkflow.net.build import TFNet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optinos = {\n",
    "    'model': 'cfg/yolo.cfg',\n",
    "    'load': 'bin/yolo.weights',\n",
    "    'threshold': 0.3,\n",
    "    'gpu': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./cfg/yolo.cfg\n",
      "Parsing cfg/yolo.cfg\n",
      "Loading bin/yolo.weights ...\n",
      "Successfully identified 203934260 bytes\n",
      "Finished in 0.05086064338684082s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 608, 608, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "GPU mode with 1.0 usage\n",
      "Finished in 72.92363810539246s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfnet = TFNet(optinos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting_people(name_of_video):\n",
    "    global tracker\n",
    "    cap = cv2.VideoCapture(name_of_video)\n",
    "    w = cap.get(3)\n",
    "    h = cap.get(4)\n",
    "    frameArea = h*w\n",
    "    areaTH = frameArea/250\n",
    "    person = {}\n",
    "    index_of_people = '1'\n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=True)\n",
    "    \n",
    "    kernelOp = np.ones((3,3), np.uint8)\n",
    "    kernelCl = np.ones((11,11), np.uint8)\n",
    "    \n",
    "    ok, frame = cap.read()\n",
    "    lines = transform.points_to_lines(draw.draw(\"Test_draw\", frame))\n",
    "    \n",
    "    print(lines)\n",
    "    \n",
    "    while(cap.isOpened()):\n",
    "        ok, frame = cap.read()\n",
    "        fgmask = fgbg.apply(frame)\n",
    "        try:\n",
    "            ret, imBin = cv2.threshold(fgmask, 200, 255, cv2.THRESH_BINARY)\n",
    "            mask = cv2.morphologyEx(imBin, cv2.MORPH_OPEN, kernelOp)\n",
    "            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernelCl)\n",
    "        except:\n",
    "            print('EOF')\n",
    "            break\n",
    "\n",
    "        _, contours0, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        for cnt in contours0:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            M = cv2.moments(cnt)\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            if position.in_rectangle(lines, (cx,cy)):\n",
    "                if area > areaTH:\n",
    "                    x,y,w,h = cv2.boundingRect(cnt)\n",
    "                    cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "                    cv2.line(frame, (cx,cy), (cx,cy), (0,255,0), 2)\n",
    "                    box = [x, y, x+w, y+h]\n",
    "                    M = cv2.moments(cnt)\n",
    "                    cx = int(M['m10']/M['m00'])\n",
    "                    cy = int(M['m01']/M['m00'])\n",
    "                    cv2.imshow(\"Test\", frame[y:y+h,x:x+h])\n",
    "                    ###########\n",
    "                    new = True\n",
    "                    for key in person:\n",
    "                        #print(key, person[key], type(person[key]))\n",
    "                        if abs(x-person[key].get_x()) <= w and abs(y - person[key].get_y()) <= h:\n",
    "                            new = False\n",
    "                            person[key].update_coordinates(x, y, w, h)\n",
    "                            #p = tracker.multi_track(list(person.keys()), frame[:,:,-1])\n",
    "                            break\n",
    "                    if new == True:\n",
    "                        p = Person.Person(index_of_people, x, y, h, w)\n",
    "                        person[index_of_people] = p\n",
    "                        #p = tracker.multi_track(list(person.keys()), frame[:,:,-1], {index_of_people : box})\n",
    "                        index_of_people = str(int(index_of_people) + 1)\n",
    "                    ###########    \n",
    "\n",
    "        try:\n",
    "            cv2.rectangle(frame, lines['top_line']['coordinates'][0], lines['down_line']['coordinates'][0], (255,255,255), 1)\n",
    "            cv2.line(frame, lines['red_up_line']['coordinates'][0], lines['red_up_line']['coordinates'][1], (0,0,255), 2)\n",
    "            cv2.line(frame, lines['blue_down_line']['coordinates'][0], lines['blue_down_line']['coordinates'][1], (255,0,0), 2)\n",
    "            cv2.imshow('Count people',frame)\n",
    "        except:\n",
    "            print('EOF')\n",
    "            break\n",
    "        k = cv2.waitKey(20) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return person, lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ilya\\Kyrsach\\Kyrsovaya\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'top_line': {'function': <function points_to_lines.<locals>.line.<locals>.pre_line at 0x0000022F53E22950>, 'coordinates': [(453, 5), (621, 5)]}, 'down_line': {'function': <function points_to_lines.<locals>.line.<locals>.pre_line at 0x0000022F53E22AE8>, 'coordinates': [(621, 456), (453, 456)]}, 'right_line': {'function': <function points_to_lines.<locals>.line.<locals>.pre_line at 0x0000022F53E22A60>, 'coordinates': [(621, 5), (621, 456)]}, 'left_line': {'function': <function points_to_lines.<locals>.line.<locals>.pre_line at 0x0000022F53E229D8>, 'coordinates': [(453, 456), (453, 5)]}, 'red_up_line': {'function': <function points_to_lines.<locals>.line.<locals>.pre_line at 0x0000022F53E22C80>, 'coordinates': [(454, 99), (622, 94)]}, 'blue_down_line': {'function': <function points_to_lines.<locals>.line.<locals>.pre_line at 0x0000022F53E22BF8>, 'coordinates': [(454, 198), (622, 189)]}}\n",
      "EOF\n"
     ]
    }
   ],
   "source": [
    "p, lines = counting_people('./data/peopleCounter.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Threshold 1228.8\n",
      "Red line y: 288\n",
      "Blue line y: 192\n",
      "[[[  0 288]]\n",
      "\n",
      " [[640 288]]]\n",
      "ID: 1 crossed going down at Sat Apr 28 15:33:54 2018\n",
      "ID: 2 crossed going down at Sat Apr 28 15:33:57 2018\n",
      "ID: 3 crossed going down at Sat Apr 28 15:34:00 2018\n",
      "ID: 5 crossed going up at Sat Apr 28 15:34:00 2018\n",
      "ID: 7 crossed going down at Sat Apr 28 15:34:01 2018\n",
      "ID: 11 crossed going down at Sat Apr 28 15:34:02 2018\n",
      "ID: 9 crossed going up at Sat Apr 28 15:34:02 2018\n",
      "ID: 7 crossed going up at Sat Apr 28 15:34:02 2018\n",
      "ID: 13 crossed going down at Sat Apr 28 15:34:05 2018\n",
      "EOF\n",
      "UP: 3\n",
      "DOWN: 6\n"
     ]
    }
   ],
   "source": [
    "import Person\n",
    "import time\n",
    "\n",
    "\n",
    "cnt_up   = 0\n",
    "cnt_down = 0\n",
    "\n",
    "cap = cv2.VideoCapture('./data/peopleCounter.avi')\n",
    "\n",
    "w = cap.get(3)\n",
    "h = cap.get(4)\n",
    "frameArea = h*w\n",
    "areaTH = frameArea/250\n",
    "print('Area Threshold', areaTH)\n",
    "\n",
    "#Lineas de entrada/salida\n",
    "line_up = int(2*(h/5))\n",
    "line_down   = int(3*(h/5))\n",
    "\n",
    "up_limit =   int(1*(h/5))\n",
    "down_limit = int(4*(h/5))\n",
    "\n",
    "print(\"Red line y:\",str(line_down))\n",
    "print(\"Blue line y:\", str(line_up))\n",
    "line_down_color = (255,0,0)\n",
    "line_up_color = (0,0,255)\n",
    "pt1 =  [0, line_down];\n",
    "pt2 =  [w, line_down];\n",
    "pts_L1 = np.array([pt1,pt2], np.int32)\n",
    "pts_L1 = pts_L1.reshape((-1,1,2))\n",
    "print(pts_L1)\n",
    "pt3 =  [0, line_up];\n",
    "pt4 =  [w, line_up];\n",
    "pts_L2 = np.array([pt3,pt4], np.int32)\n",
    "pts_L2 = pts_L2.reshape((-1,1,2))\n",
    "\n",
    "pt5 =  [0, up_limit];\n",
    "pt6 =  [w, up_limit];\n",
    "pts_L3 = np.array([pt5,pt6], np.int32)\n",
    "pts_L3 = pts_L3.reshape((-1,1,2))\n",
    "pt7 =  [0, down_limit];\n",
    "pt8 =  [w, down_limit];\n",
    "pts_L4 = np.array([pt7,pt8], np.int32)\n",
    "pts_L4 = pts_L4.reshape((-1,1,2))\n",
    "\n",
    "#Substractor de fondo\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows = True)\n",
    "\n",
    "#Elementos estructurantes para filtros morfoogicos\n",
    "kernelOp = np.ones((3,3),np.uint8)\n",
    "kernelOp2 = np.ones((5,5),np.uint8)\n",
    "kernelCl = np.ones((11,11),np.uint8)\n",
    "\n",
    "#Variables\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "persons = []\n",
    "max_p_age = 5\n",
    "pid = 1\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    for i in persons:\n",
    "        i.age_one() #age every person one frame\n",
    "    #########################\n",
    "    #   PRE-PROCESAMIENTO   #\n",
    "    #########################\n",
    "    \n",
    "    #Aplica substraccion de fondo\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    fgmask2 = fgbg.apply(frame)\n",
    "\n",
    "    #Binariazcion para eliminar sombras (color gris)\n",
    "    try:\n",
    "        ret,imBin= cv2.threshold(fgmask,200,255,cv2.THRESH_BINARY)\n",
    "        ret,imBin2 = cv2.threshold(fgmask2,200,255,cv2.THRESH_BINARY)\n",
    "        #Opening (erode->dilate) para quitar ruido.\n",
    "        mask = cv2.morphologyEx(imBin, cv2.MORPH_OPEN, kernelOp)\n",
    "        mask2 = cv2.morphologyEx(imBin2, cv2.MORPH_OPEN, kernelOp)\n",
    "        #Closing (dilate -> erode) para juntar regiones blancas.\n",
    "        mask =  cv2.morphologyEx(mask , cv2.MORPH_CLOSE, kernelCl)\n",
    "        mask2 = cv2.morphologyEx(mask2, cv2.MORPH_CLOSE, kernelCl)\n",
    "    except:\n",
    "        print('EOF')\n",
    "        print('UP:',cnt_up)\n",
    "        print('DOWN:',cnt_down)\n",
    "        break\n",
    "    #################\n",
    "    #   CONTORNOS   #\n",
    "    #################\n",
    "    \n",
    "    # RETR_EXTERNAL returns only extreme outer flags. All child contours are left behind.\n",
    "    _, contours0, hierarchy = cv2.findContours(mask2,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours0:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > areaTH:\n",
    "            #################\n",
    "            #   TRACKING    #\n",
    "            #################\n",
    "            \n",
    "            #Falta agregar condiciones para multipersonas, salidas y entradas de pantalla.\n",
    "            \n",
    "            M = cv2.moments(cnt)\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            #results = tfnet.return_predict(frame[y:y+h,x:x+h,:])\n",
    "            #print(results)\n",
    "            new = True\n",
    "            if cy in range(up_limit,down_limit):\n",
    "                for i in persons:\n",
    "                    if (abs(cx-i.getX()) <= w and abs(cy-i.getY()) <= h):\n",
    "                        # el objeto esta cerca de uno que ya se detecto antes\n",
    "                        new = False\n",
    "                        i.updateCoords(cx,cy)   #actualiza coordenadas en el objeto and resets age\n",
    "                        if i.going_UP(line_down,line_up) == True:\n",
    "                            cnt_up += 1;\n",
    "                            print(\"ID:\",i.getId(),'crossed going up at',time.strftime(\"%c\"))\n",
    "                        elif i.going_DOWN(line_down,line_up) == True:\n",
    "                            cnt_down += 1;\n",
    "                            print(\"ID:\",i.getId(),'crossed going down at',time.strftime(\"%c\"))\n",
    "                        break\n",
    "                    if i.getState() == '1':\n",
    "                        if i.getDir() == 'down' and i.getY() > down_limit:\n",
    "                            i.setDone()\n",
    "                        elif i.getDir() == 'up' and i.getY() < up_limit:\n",
    "                            i.setDone()\n",
    "                    if i.timedOut():\n",
    "                        #sacar i de la lista persons\n",
    "                        index = persons.index(i)\n",
    "                        persons.pop(index)\n",
    "                        del i     #liberar la memoria de i\n",
    "                if new == True:\n",
    "                    p = Person.MyPerson(pid,cx,cy, max_p_age)\n",
    "                    persons.append(p)\n",
    "                    pid += 1     \n",
    "            #################\n",
    "            #   DIBUJOS     #\n",
    "            #################\n",
    "            cv2.circle(frame,(cx,cy), 5, (0,0,255), -1)\n",
    "            img = cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)            \n",
    "            #cv2.drawContours(frame, cnt, -1, (0,255,0), 3)\n",
    "            \n",
    "    #END for cnt in contours0\n",
    "            \n",
    "    #########################\n",
    "    # DIBUJAR TRAYECTORIAS  #\n",
    "    #########################\n",
    "    for i in persons:\n",
    "        if len(i.getTracks()) >= 2:\n",
    "            pts = np.array(i.getTracks(), np.int32)\n",
    "            pts = pts.reshape((-1,1,2))\n",
    "            frame = cv2.polylines(frame,[pts],False,i.getRGB())\n",
    "       \n",
    "        cv2.putText(frame, str(i.getId()),(i.getX(),i.getY()),font,1,i.getRGB(),1,cv2.LINE_AA)\n",
    "        \n",
    "    #################\n",
    "    #   IMAGANES    #\n",
    "    #################\n",
    "    str_up = 'UP: '+ str(cnt_up)\n",
    "    str_down = 'DOWN: '+ str(cnt_down)\n",
    "    frame = cv2.polylines(frame,[pts_L1],False,line_down_color,thickness=2)\n",
    "    frame = cv2.polylines(frame,[pts_L2],False,line_up_color,thickness=2)\n",
    "    frame = cv2.polylines(frame,[pts_L3],False,(255,255,255),thickness=1)\n",
    "    frame = cv2.polylines(frame,[pts_L4],False,(255,255,255),thickness=1)\n",
    "    cv2.putText(frame, str_up ,(10,40),font,0.5,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(frame, str_up ,(10,40),font,0.5,(0,0,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(frame, str_down ,(10,90),font,0.5,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(frame, str_down ,(10,90),font,0.5,(255,0,0),1,cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Frame',frame)\n",
    "    #cv2.imshow('Mask',mask)    \n",
    "    \n",
    "    #preisonar ESC para salir\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "#END while(cap.isOpened())\n",
    "    \n",
    "#################\n",
    "#   LIMPIEZA    #\n",
    "#################\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'1':{'gf':7},'2':{'x':5},'3':{'y':1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'gf': 7}, '2': {'x': 5}, '3': {'y': 1}}\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = p.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1', '2', '3'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring:\n",
      "re3/conv1/W_conv -> [11, 11, 3, 96] = 0.139392MB\n",
      "re3/conv1/b_conv -> [96] = 0.000384MB\n",
      "re3/conv1_skip/W_conv -> [1, 1, 96, 16] = 0.006144MB\n",
      "re3/conv1_skip/b_conv -> [16] = 6.4e-05MB\n",
      "re3/conv1_skip/prelu -> [16] = 6.4e-05MB\n",
      "re3/conv2/W_conv -> [5, 5, 48, 256] = 1.2288MB\n",
      "re3/conv2/b_conv -> [256] = 0.001024MB\n",
      "re3/conv2_skip/W_conv -> [1, 1, 256, 32] = 0.032768MB\n",
      "re3/conv2_skip/b_conv -> [32] = 0.000128MB\n",
      "re3/conv2_skip/prelu -> [32] = 0.000128MB\n",
      "re3/conv3/W_conv -> [3, 3, 256, 384] = 3.538944MB\n",
      "re3/conv3/b_conv -> [384] = 0.001536MB\n",
      "re3/conv4/W_conv -> [3, 3, 192, 384] = 2.654208MB\n",
      "re3/conv4/b_conv -> [384] = 0.001536MB\n",
      "re3/conv5/W_conv -> [3, 3, 192, 256] = 1.769472MB\n",
      "re3/conv5/b_conv -> [256] = 0.001024MB\n",
      "re3/conv5_skip/W_conv -> [1, 1, 256, 64] = 0.065536MB\n",
      "re3/conv5_skip/b_conv -> [64] = 0.000256MB\n",
      "re3/conv5_skip/prelu -> [64] = 0.000256MB\n",
      "re3/fc6/W_fc -> [74208, 2048] = 607.911936MB\n",
      "re3/fc6/b_fc -> [2048] = 0.008192MB\n",
      "re3/fc_output/W_fc -> [1024, 4] = 0.016384MB\n",
      "re3/fc_output/b_fc -> [4] = 1.6e-05MB\n",
      "re3/lstm1/rnn/LSTM/block_input/biases -> [1024] = 0.004096MB\n",
      "re3/lstm1/rnn/LSTM/block_input/weights -> [3072, 1024] = 12.582912MB\n",
      "re3/lstm1/rnn/LSTM/forget_gate/biases -> [1024] = 0.004096MB\n",
      "re3/lstm1/rnn/LSTM/forget_gate/weights -> [4096, 1024] = 16.777216MB\n",
      "re3/lstm1/rnn/LSTM/input_gate/biases -> [1024] = 0.004096MB\n",
      "re3/lstm1/rnn/LSTM/input_gate/weights -> [4096, 1024] = 16.777216MB\n",
      "re3/lstm1/rnn/LSTM/output_gate/biases -> [1024] = 0.004096MB\n",
      "re3/lstm1/rnn/LSTM/output_gate/weights -> [4096, 1024] = 16.777216MB\n",
      "re3/lstm2/rnn/LSTM/block_input/biases -> [1024] = 0.004096MB\n",
      "re3/lstm2/rnn/LSTM/block_input/weights -> [4096, 1024] = 16.777216MB\n",
      "re3/lstm2/rnn/LSTM/forget_gate/biases -> [1024] = 0.004096MB\n",
      "re3/lstm2/rnn/LSTM/forget_gate/weights -> [5120, 1024] = 20.97152MB\n",
      "re3/lstm2/rnn/LSTM/input_gate/biases -> [1024] = 0.004096MB\n",
      "re3/lstm2/rnn/LSTM/input_gate/weights -> [5120, 1024] = 20.97152MB\n",
      "re3/lstm2/rnn/LSTM/output_gate/biases -> [1024] = 0.004096MB\n",
      "re3/lstm2/rnn/LSTM/output_gate/weights -> [5120, 1024] = 20.97152MB\n",
      "\n",
      "\n",
      "Did not restore:beta1_power\n",
      "\tbeta2_power\n",
      "\tglobal_step\n",
      "\tre3/conv1/W_conv/Adam\n",
      "\tre3/conv1/W_conv/Adam_1\n",
      "\tre3/conv1/b_conv/Adam\n",
      "\tre3/conv1/b_conv/Adam_1\n",
      "\tre3/conv1_skip/W_conv/Adam\n",
      "\tre3/conv1_skip/W_conv/Adam_1\n",
      "\tre3/conv1_skip/b_conv/Adam\n",
      "\tre3/conv1_skip/b_conv/Adam_1\n",
      "\tre3/conv1_skip/prelu/Adam\n",
      "\tre3/conv1_skip/prelu/Adam_1\n",
      "\tre3/conv2/W_conv/Adam\n",
      "\tre3/conv2/W_conv/Adam_1\n",
      "\tre3/conv2/b_conv/Adam\n",
      "\tre3/conv2/b_conv/Adam_1\n",
      "\tre3/conv2_skip/W_conv/Adam\n",
      "\tre3/conv2_skip/W_conv/Adam_1\n",
      "\tre3/conv2_skip/b_conv/Adam\n",
      "\tre3/conv2_skip/b_conv/Adam_1\n",
      "\tre3/conv2_skip/prelu/Adam\n",
      "\tre3/conv2_skip/prelu/Adam_1\n",
      "\tre3/conv3/W_conv/Adam\n",
      "\tre3/conv3/W_conv/Adam_1\n",
      "\tre3/conv3/b_conv/Adam\n",
      "\tre3/conv3/b_conv/Adam_1\n",
      "\tre3/conv4/W_conv/Adam\n",
      "\tre3/conv4/W_conv/Adam_1\n",
      "\tre3/conv4/b_conv/Adam\n",
      "\tre3/conv4/b_conv/Adam_1\n",
      "\tre3/conv5/W_conv/Adam\n",
      "\tre3/conv5/W_conv/Adam_1\n",
      "\tre3/conv5/b_conv/Adam\n",
      "\tre3/conv5/b_conv/Adam_1\n",
      "\tre3/conv5_skip/W_conv/Adam\n",
      "\tre3/conv5_skip/W_conv/Adam_1\n",
      "\tre3/conv5_skip/b_conv/Adam\n",
      "\tre3/conv5_skip/b_conv/Adam_1\n",
      "\tre3/conv5_skip/prelu/Adam\n",
      "\tre3/conv5_skip/prelu/Adam_1\n",
      "\tre3/fc6/W_fc/Adam\n",
      "\tre3/fc6/W_fc/Adam_1\n",
      "\tre3/fc6/b_fc/Adam\n",
      "\tre3/fc6/b_fc/Adam_1\n",
      "\tre3/fc_output/W_fc/Adam\n",
      "\tre3/fc_output/W_fc/Adam_1\n",
      "\tre3/fc_output/b_fc/Adam\n",
      "\tre3/fc_output/b_fc/Adam_1\n",
      "\tre3/lstm1/rnn/LSTM/block_input/biases/Adam\n",
      "\tre3/lstm1/rnn/LSTM/block_input/biases/Adam_1\n",
      "\tre3/lstm1/rnn/LSTM/block_input/weights/Adam\n",
      "\tre3/lstm1/rnn/LSTM/block_input/weights/Adam_1\n",
      "\tre3/lstm1/rnn/LSTM/forget_gate/biases/Adam\n",
      "\tre3/lstm1/rnn/LSTM/forget_gate/biases/Adam_1\n",
      "\tre3/lstm1/rnn/LSTM/forget_gate/weights/Adam\n",
      "\tre3/lstm1/rnn/LSTM/forget_gate/weights/Adam_1\n",
      "\tre3/lstm1/rnn/LSTM/input_gate/biases/Adam\n",
      "\tre3/lstm1/rnn/LSTM/input_gate/biases/Adam_1\n",
      "\tre3/lstm1/rnn/LSTM/input_gate/weights/Adam\n",
      "\tre3/lstm1/rnn/LSTM/input_gate/weights/Adam_1\n",
      "\tre3/lstm1/rnn/LSTM/output_gate/biases/Adam\n",
      "\tre3/lstm1/rnn/LSTM/output_gate/biases/Adam_1\n",
      "\tre3/lstm1/rnn/LSTM/output_gate/weights/Adam\n",
      "\tre3/lstm1/rnn/LSTM/output_gate/weights/Adam_1\n",
      "\tre3/lstm2/rnn/LSTM/block_input/biases/Adam\n",
      "\tre3/lstm2/rnn/LSTM/block_input/biases/Adam_1\n",
      "\tre3/lstm2/rnn/LSTM/block_input/weights/Adam\n",
      "\tre3/lstm2/rnn/LSTM/block_input/weights/Adam_1\n",
      "\tre3/lstm2/rnn/LSTM/forget_gate/biases/Adam\n",
      "\tre3/lstm2/rnn/LSTM/forget_gate/biases/Adam_1\n",
      "\tre3/lstm2/rnn/LSTM/forget_gate/weights/Adam\n",
      "\tre3/lstm2/rnn/LSTM/forget_gate/weights/Adam_1\n",
      "\tre3/lstm2/rnn/LSTM/input_gate/biases/Adam\n",
      "\tre3/lstm2/rnn/LSTM/input_gate/biases/Adam_1\n",
      "\tre3/lstm2/rnn/LSTM/input_gate/weights/Adam\n",
      "\tre3/lstm2/rnn/LSTM/input_gate/weights/Adam_1\n",
      "\tre3/lstm2/rnn/LSTM/output_gate/biases/Adam\n",
      "\tre3/lstm2/rnn/LSTM/output_gate/biases/Adam_1\n",
      "\tre3/lstm2/rnn/LSTM/output_gate/weights/Adam\n",
      "\tre3/lstm2/rnn/LSTM/output_gate/weights/Adam_1\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/Ilya/Kyrsach/Kyrsovaya/re3-tensorflow/checkpoints\\model.ckpt-0\n",
      "Restored C:/Users/Ilya/Kyrsach/Kyrsovaya/re3-tensorflow/checkpoints\\model.ckpt-0\n"
     ]
    }
   ],
   "source": [
    "tracker = re3_tracker.Re3Tracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0bb4bdaab381>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlines\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lines' is not defined"
     ]
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
