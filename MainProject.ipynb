{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from Person import Person\n",
    "from utils import draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 're3-tensorflow/'\n",
      "C:\\Users\\velmisov\\Ilya\\Kyrsovaya\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tracker'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e0df453df808>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtracker\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre3_tracker\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tracker'"
     ]
    }
   ],
   "source": [
    "%cd re3-tensorflow/\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tracker import re3_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ilya\\Kyrsach\\Kyrsovaya\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ilya\\Kyrsach\\Kyrsovaya\\darkflow-master\n"
     ]
    }
   ],
   "source": [
    "% cd ./darkflow-master/\n",
    "from darkflow.net.build import TFNet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optinos = {\n",
    "    'model': 'cfg/yolo.cfg',\n",
    "    'load': 'bin/yolo.weights',\n",
    "    'threshold': 0.3,\n",
    "    'gpu': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./cfg/yolo.cfg\n",
      "Parsing cfg/yolo.cfg\n",
      "Loading bin/yolo.weights ...\n",
      "Successfully identified 203934260 bytes\n",
      "Finished in 0.05086064338684082s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 608, 608, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "GPU mode with 1.0 usage\n",
      "Finished in 72.92363810539246s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfnet = TFNet(optinos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting_people(name_of_video):\n",
    "    global tracker\n",
    "    cap = cv2.VideoCapture(name_of_video)\n",
    "    w = cap.get(3)\n",
    "    h = cap.get(4)\n",
    "    frameArea = h*w\n",
    "    areaTH = frameArea/250\n",
    "    person = {}\n",
    "    index_of_people = '1'\n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=True)\n",
    "    \n",
    "    kernelOp = np.ones((3,3), np.uint8)\n",
    "    kernelCl = np.ones((11,11), np.uint8)\n",
    "    \n",
    "    ok, frame = cap.read()\n",
    "    lines = draw.draw(\"Test_draw\", frame)\n",
    "    \n",
    "    while(cap.isOpened()):\n",
    "        ok, frame = cap.read()\n",
    "        fgmask = fgbg.apply(frame)\n",
    "        try:\n",
    "            ret, imBin = cv2.threshold(fgmask, 200, 255, cv2.THRESH_BINARY)\n",
    "            mask = cv2.morphologyEx(imBin, cv2.MORPH_OPEN, kernelOp)\n",
    "            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernelCl)\n",
    "        except:\n",
    "            print('EOF')\n",
    "            break\n",
    "\n",
    "        _, contours0, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        for cnt in contours0:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area > areaTH:\n",
    "                x,y,w,h = cv2.boundingRect(cnt)\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "                box = [x, y, x+w, y+h]\n",
    "                M = cv2.moments(cnt)\n",
    "                cx = int(M['m10']/M['m00'])\n",
    "                cy = int(M['m01']/M['m00'])\n",
    "                cv2.imshow(\"Test\", frame[y:y+h,x:x+h])\n",
    "                ###########\n",
    "                new = True\n",
    "                for key in person:\n",
    "                    #print(key, person[key], type(person[key]))\n",
    "                    if abs(x-person[key].get_x()) <= w and abs(y - person[key].get_y()) <= h:\n",
    "                        new = False\n",
    "                        person[key].update_coordinates(x, y, w, h)\n",
    "                        #p = tracker.multi_track(list(person.keys()), frame[:,:,-1])\n",
    "                        break\n",
    "                if new == True:\n",
    "                    p = Person.Person(index_of_people, x, y, h, w)\n",
    "                    person[index_of_people] = p\n",
    "                    #p = tracker.multi_track(list(person.keys()), frame[:,:,-1], {index_of_people : box})\n",
    "                    index_of_people = str(int(index_of_people) + 1)\n",
    "                ###########    \n",
    "            \n",
    "        try:\n",
    "            cv2.rectangle(frame, lines['intresting_zone'][0], lines['intresting_zone'][2], (255,255,255), 1)\n",
    "            cv2.line(frame, lines['red_up_line'][0], lines['red_up_line'][1], (0,0,255), 2)\n",
    "            cv2.line(frame, lines['blue_down_line'][0], lines['blue_down_line'][1], (255,0,0), 2)\n",
    "            cv2.imshow('Count people',frame)\n",
    "        except:\n",
    "            print('EOF')\n",
    "            break\n",
    "        k = cv2.waitKey(20) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return person, lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ilya\\Kyrsach\\Kyrsovaya\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, lines = counting_people('./data/peopleCounter.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Threshold 1228.8\n",
      "Red line y: 288\n",
      "Blue line y: 192\n",
      "[[[  0 288]]\n",
      "\n",
      " [[640 288]]]\n",
      "ID: 1 crossed going down at Sat Apr 28 15:33:54 2018\n",
      "ID: 2 crossed going down at Sat Apr 28 15:33:57 2018\n",
      "ID: 3 crossed going down at Sat Apr 28 15:34:00 2018\n",
      "ID: 5 crossed going up at Sat Apr 28 15:34:00 2018\n",
      "ID: 7 crossed going down at Sat Apr 28 15:34:01 2018\n",
      "ID: 11 crossed going down at Sat Apr 28 15:34:02 2018\n",
      "ID: 9 crossed going up at Sat Apr 28 15:34:02 2018\n",
      "ID: 7 crossed going up at Sat Apr 28 15:34:02 2018\n",
      "ID: 13 crossed going down at Sat Apr 28 15:34:05 2018\n",
      "EOF\n",
      "UP: 3\n",
      "DOWN: 6\n"
     ]
    }
   ],
   "source": [
    "import Person\n",
    "import time\n",
    "\n",
    "\n",
    "cnt_up   = 0\n",
    "cnt_down = 0\n",
    "\n",
    "cap = cv2.VideoCapture('./data/peopleCounter.avi')\n",
    "\n",
    "w = cap.get(3)\n",
    "h = cap.get(4)\n",
    "frameArea = h*w\n",
    "areaTH = frameArea/250\n",
    "print('Area Threshold', areaTH)\n",
    "\n",
    "#Lineas de entrada/salida\n",
    "line_up = int(2*(h/5))\n",
    "line_down   = int(3*(h/5))\n",
    "\n",
    "up_limit =   int(1*(h/5))\n",
    "down_limit = int(4*(h/5))\n",
    "\n",
    "print(\"Red line y:\",str(line_down))\n",
    "print(\"Blue line y:\", str(line_up))\n",
    "line_down_color = (255,0,0)\n",
    "line_up_color = (0,0,255)\n",
    "pt1 =  [0, line_down];\n",
    "pt2 =  [w, line_down];\n",
    "pts_L1 = np.array([pt1,pt2], np.int32)\n",
    "pts_L1 = pts_L1.reshape((-1,1,2))\n",
    "print(pts_L1)\n",
    "pt3 =  [0, line_up];\n",
    "pt4 =  [w, line_up];\n",
    "pts_L2 = np.array([pt3,pt4], np.int32)\n",
    "pts_L2 = pts_L2.reshape((-1,1,2))\n",
    "\n",
    "pt5 =  [0, up_limit];\n",
    "pt6 =  [w, up_limit];\n",
    "pts_L3 = np.array([pt5,pt6], np.int32)\n",
    "pts_L3 = pts_L3.reshape((-1,1,2))\n",
    "pt7 =  [0, down_limit];\n",
    "pt8 =  [w, down_limit];\n",
    "pts_L4 = np.array([pt7,pt8], np.int32)\n",
    "pts_L4 = pts_L4.reshape((-1,1,2))\n",
    "\n",
    "#Substractor de fondo\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows = True)\n",
    "\n",
    "#Elementos estructurantes para filtros morfoogicos\n",
    "kernelOp = np.ones((3,3),np.uint8)\n",
    "kernelOp2 = np.ones((5,5),np.uint8)\n",
    "kernelCl = np.ones((11,11),np.uint8)\n",
    "\n",
    "#Variables\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "persons = []\n",
    "max_p_age = 5\n",
    "pid = 1\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    for i in persons:\n",
    "        i.age_one() #age every person one frame\n",
    "    #########################\n",
    "    #   PRE-PROCESAMIENTO   #\n",
    "    #########################\n",
    "    \n",
    "    #Aplica substraccion de fondo\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    fgmask2 = fgbg.apply(frame)\n",
    "\n",
    "    #Binariazcion para eliminar sombras (color gris)\n",
    "    try:\n",
    "        ret,imBin= cv2.threshold(fgmask,200,255,cv2.THRESH_BINARY)\n",
    "        ret,imBin2 = cv2.threshold(fgmask2,200,255,cv2.THRESH_BINARY)\n",
    "        #Opening (erode->dilate) para quitar ruido.\n",
    "        mask = cv2.morphologyEx(imBin, cv2.MORPH_OPEN, kernelOp)\n",
    "        mask2 = cv2.morphologyEx(imBin2, cv2.MORPH_OPEN, kernelOp)\n",
    "        #Closing (dilate -> erode) para juntar regiones blancas.\n",
    "        mask =  cv2.morphologyEx(mask , cv2.MORPH_CLOSE, kernelCl)\n",
    "        mask2 = cv2.morphologyEx(mask2, cv2.MORPH_CLOSE, kernelCl)\n",
    "    except:\n",
    "        print('EOF')\n",
    "        print('UP:',cnt_up)\n",
    "        print('DOWN:',cnt_down)\n",
    "        break\n",
    "    #################\n",
    "    #   CONTORNOS   #\n",
    "    #################\n",
    "    \n",
    "    # RETR_EXTERNAL returns only extreme outer flags. All child contours are left behind.\n",
    "    _, contours0, hierarchy = cv2.findContours(mask2,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours0:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > areaTH:\n",
    "            #################\n",
    "            #   TRACKING    #\n",
    "            #################\n",
    "            \n",
    "            #Falta agregar condiciones para multipersonas, salidas y entradas de pantalla.\n",
    "            \n",
    "            M = cv2.moments(cnt)\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            #results = tfnet.return_predict(frame[y:y+h,x:x+h,:])\n",
    "            #print(results)\n",
    "            new = True\n",
    "            if cy in range(up_limit,down_limit):\n",
    "                for i in persons:\n",
    "                    if (abs(cx-i.getX()) <= w and abs(cy-i.getY()) <= h):\n",
    "                        # el objeto esta cerca de uno que ya se detecto antes\n",
    "                        new = False\n",
    "                        i.updateCoords(cx,cy)   #actualiza coordenadas en el objeto and resets age\n",
    "                        if i.going_UP(line_down,line_up) == True:\n",
    "                            cnt_up += 1;\n",
    "                            print(\"ID:\",i.getId(),'crossed going up at',time.strftime(\"%c\"))\n",
    "                        elif i.going_DOWN(line_down,line_up) == True:\n",
    "                            cnt_down += 1;\n",
    "                            print(\"ID:\",i.getId(),'crossed going down at',time.strftime(\"%c\"))\n",
    "                        break\n",
    "                    if i.getState() == '1':\n",
    "                        if i.getDir() == 'down' and i.getY() > down_limit:\n",
    "                            i.setDone()\n",
    "                        elif i.getDir() == 'up' and i.getY() < up_limit:\n",
    "                            i.setDone()\n",
    "                    if i.timedOut():\n",
    "                        #sacar i de la lista persons\n",
    "                        index = persons.index(i)\n",
    "                        persons.pop(index)\n",
    "                        del i     #liberar la memoria de i\n",
    "                if new == True:\n",
    "                    p = Person.MyPerson(pid,cx,cy, max_p_age)\n",
    "                    persons.append(p)\n",
    "                    pid += 1     \n",
    "            #################\n",
    "            #   DIBUJOS     #\n",
    "            #################\n",
    "            cv2.circle(frame,(cx,cy), 5, (0,0,255), -1)\n",
    "            img = cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)            \n",
    "            #cv2.drawContours(frame, cnt, -1, (0,255,0), 3)\n",
    "            \n",
    "    #END for cnt in contours0\n",
    "            \n",
    "    #########################\n",
    "    # DIBUJAR TRAYECTORIAS  #\n",
    "    #########################\n",
    "    for i in persons:\n",
    "        if len(i.getTracks()) >= 2:\n",
    "            pts = np.array(i.getTracks(), np.int32)\n",
    "            pts = pts.reshape((-1,1,2))\n",
    "            frame = cv2.polylines(frame,[pts],False,i.getRGB())\n",
    "       \n",
    "        cv2.putText(frame, str(i.getId()),(i.getX(),i.getY()),font,1,i.getRGB(),1,cv2.LINE_AA)\n",
    "        \n",
    "    #################\n",
    "    #   IMAGANES    #\n",
    "    #################\n",
    "    str_up = 'UP: '+ str(cnt_up)\n",
    "    str_down = 'DOWN: '+ str(cnt_down)\n",
    "    frame = cv2.polylines(frame,[pts_L1],False,line_down_color,thickness=2)\n",
    "    frame = cv2.polylines(frame,[pts_L2],False,line_up_color,thickness=2)\n",
    "    frame = cv2.polylines(frame,[pts_L3],False,(255,255,255),thickness=1)\n",
    "    frame = cv2.polylines(frame,[pts_L4],False,(255,255,255),thickness=1)\n",
    "    cv2.putText(frame, str_up ,(10,40),font,0.5,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(frame, str_up ,(10,40),font,0.5,(0,0,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(frame, str_down ,(10,90),font,0.5,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(frame, str_down ,(10,90),font,0.5,(255,0,0),1,cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Frame',frame)\n",
    "    #cv2.imshow('Mask',mask)    \n",
    "    \n",
    "    #preisonar ESC para salir\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "#END while(cap.isOpened())\n",
    "    \n",
    "#################\n",
    "#   LIMPIEZA    #\n",
    "#################\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'1':{'gf':7},'2':{'x':5},'3':{'y':1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'gf': 7}, '2': {'x': 5}, '3': {'y': 1}}\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = p.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1', '2', '3'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring:\n",
      "re3/conv1/W_conv -> [11, 11, 3, 96] = 0.139392MB\n",
      "re3/conv1/b_conv -> [96] = 0.000384MB\n",
      "re3/conv1_skip/W_conv -> [1, 1, 96, 16] = 0.006144MB\n",
      "re3/conv1_skip/b_conv -> [16] = 6.4e-05MB\n",
      "re3/conv1_skip/prelu -> [16] = 6.4e-05MB\n",
      "re3/conv2/W_conv -> [5, 5, 48, 256] = 1.2288MB\n",
      "re3/conv2/b_conv -> [256] = 0.001024MB\n",
      "re3/conv2_skip/W_conv -> [1, 1, 256, 32] = 0.032768MB\n",
      "re3/conv2_skip/b_conv -> [32] = 0.000128MB\n",
      "re3/conv2_skip/prelu -> [32] = 0.000128MB\n",
      "re3/conv3/W_conv -> [3, 3, 256, 384] = 3.538944MB\n",
      "re3/conv3/b_conv -> [384] = 0.001536MB\n",
      "re3/conv4/W_conv -> [3, 3, 192, 384] = 2.654208MB\n",
      "re3/conv4/b_conv -> [384] = 0.001536MB\n",
      "re3/conv5/W_conv -> [3, 3, 192, 256] = 1.769472MB\n",
      "re3/conv5/b_conv -> [256] = 0.001024MB\n",
      "re3/conv5_skip/W_conv -> [1, 1, 256, 64] = 0.065536MB\n",
      "re3/conv5_skip/b_conv -> [64] = 0.000256MB\n",
      "re3/conv5_skip/prelu -> [64] = 0.000256MB\n",
      "re3/fc6/W_fc -> [74208, 2048] = 607.911936MB\n",
      "re3/fc6/b_fc -> [2048] = 0.008192MB\n",
      "re3/fc_output/W_fc -> [1024, 4] = 0.016384MB\n",
      "re3/fc_output/b_fc -> [4] = 1.6e-05MB\n",
      "re3/lstm1/rnn/LSTM/block_input/biases -> [1024] = 0.004096MB\n",
      "re3/lstm1/rnn/LSTM/block_input/weights -> [3072, 1024] = 12.582912MB\n",
      "re3/lstm1/rnn/LSTM/forget_gate/biases -> [1024] = 0.004096MB\n",
      "re3/lstm1/rnn/LSTM/forget_gate/weights -> [4096, 1024] = 16.777216MB\n",
      "re3/lstm1/rnn/LSTM/input_gate/biases -> [1024] = 0.004096MB\n",
      "re3/lstm1/rnn/LSTM/input_gate/weights -> [4096, 1024] = 16.777216MB\n",
      "re3/lstm1/rnn/LSTM/output_gate/biases -> [1024] = 0.004096MB\n",
      "re3/lstm1/rnn/LSTM/output_gate/weights -> [4096, 1024] = 16.777216MB\n",
      "re3/lstm2/rnn/LSTM/block_input/biases -> [1024] = 0.004096MB\n",
      "re3/lstm2/rnn/LSTM/block_input/weights -> [4096, 1024] = 16.777216MB\n",
      "re3/lstm2/rnn/LSTM/forget_gate/biases -> [1024] = 0.004096MB\n",
      "re3/lstm2/rnn/LSTM/forget_gate/weights -> [5120, 1024] = 20.97152MB\n",
      "re3/lstm2/rnn/LSTM/input_gate/biases -> [1024] = 0.004096MB\n",
      "re3/lstm2/rnn/LSTM/input_gate/weights -> [5120, 1024] = 20.97152MB\n",
      "re3/lstm2/rnn/LSTM/output_gate/biases -> [1024] = 0.004096MB\n",
      "re3/lstm2/rnn/LSTM/output_gate/weights -> [5120, 1024] = 20.97152MB\n",
      "\n",
      "\n",
      "Did not restore:beta1_power\n",
      "\tbeta2_power\n",
      "\tglobal_step\n",
      "\tre3/conv1/W_conv/Adam\n",
      "\tre3/conv1/W_conv/Adam_1\n",
      "\tre3/conv1/b_conv/Adam\n",
      "\tre3/conv1/b_conv/Adam_1\n",
      "\tre3/conv1_skip/W_conv/Adam\n",
      "\tre3/conv1_skip/W_conv/Adam_1\n",
      "\tre3/conv1_skip/b_conv/Adam\n",
      "\tre3/conv1_skip/b_conv/Adam_1\n",
      "\tre3/conv1_skip/prelu/Adam\n",
      "\tre3/conv1_skip/prelu/Adam_1\n",
      "\tre3/conv2/W_conv/Adam\n",
      "\tre3/conv2/W_conv/Adam_1\n",
      "\tre3/conv2/b_conv/Adam\n",
      "\tre3/conv2/b_conv/Adam_1\n",
      "\tre3/conv2_skip/W_conv/Adam\n",
      "\tre3/conv2_skip/W_conv/Adam_1\n",
      "\tre3/conv2_skip/b_conv/Adam\n",
      "\tre3/conv2_skip/b_conv/Adam_1\n",
      "\tre3/conv2_skip/prelu/Adam\n",
      "\tre3/conv2_skip/prelu/Adam_1\n",
      "\tre3/conv3/W_conv/Adam\n",
      "\tre3/conv3/W_conv/Adam_1\n",
      "\tre3/conv3/b_conv/Adam\n",
      "\tre3/conv3/b_conv/Adam_1\n",
      "\tre3/conv4/W_conv/Adam\n",
      "\tre3/conv4/W_conv/Adam_1\n",
      "\tre3/conv4/b_conv/Adam\n",
      "\tre3/conv4/b_conv/Adam_1\n",
      "\tre3/conv5/W_conv/Adam\n",
      "\tre3/conv5/W_conv/Adam_1\n",
      "\tre3/conv5/b_conv/Adam\n",
      "\tre3/conv5/b_conv/Adam_1\n",
      "\tre3/conv5_skip/W_conv/Adam\n",
      "\tre3/conv5_skip/W_conv/Adam_1\n",
      "\tre3/conv5_skip/b_conv/Adam\n",
      "\tre3/conv5_skip/b_conv/Adam_1\n",
      "\tre3/conv5_skip/prelu/Adam\n",
      "\tre3/conv5_skip/prelu/Adam_1\n",
      "\tre3/fc6/W_fc/Adam\n",
      "\tre3/fc6/W_fc/Adam_1\n",
      "\tre3/fc6/b_fc/Adam\n",
      "\tre3/fc6/b_fc/Adam_1\n",
      "\tre3/fc_output/W_fc/Adam\n",
      "\tre3/fc_output/W_fc/Adam_1\n",
      "\tre3/fc_output/b_fc/Adam\n",
      "\tre3/fc_output/b_fc/Adam_1\n",
      "\tre3/lstm1/rnn/LSTM/block_input/biases/Adam\n",
      "\tre3/lstm1/rnn/LSTM/block_input/biases/Adam_1\n",
      "\tre3/lstm1/rnn/LSTM/block_input/weights/Adam\n",
      "\tre3/lstm1/rnn/LSTM/block_input/weights/Adam_1\n",
      "\tre3/lstm1/rnn/LSTM/forget_gate/biases/Adam\n",
      "\tre3/lstm1/rnn/LSTM/forget_gate/biases/Adam_1\n",
      "\tre3/lstm1/rnn/LSTM/forget_gate/weights/Adam\n",
      "\tre3/lstm1/rnn/LSTM/forget_gate/weights/Adam_1\n",
      "\tre3/lstm1/rnn/LSTM/input_gate/biases/Adam\n",
      "\tre3/lstm1/rnn/LSTM/input_gate/biases/Adam_1\n",
      "\tre3/lstm1/rnn/LSTM/input_gate/weights/Adam\n",
      "\tre3/lstm1/rnn/LSTM/input_gate/weights/Adam_1\n",
      "\tre3/lstm1/rnn/LSTM/output_gate/biases/Adam\n",
      "\tre3/lstm1/rnn/LSTM/output_gate/biases/Adam_1\n",
      "\tre3/lstm1/rnn/LSTM/output_gate/weights/Adam\n",
      "\tre3/lstm1/rnn/LSTM/output_gate/weights/Adam_1\n",
      "\tre3/lstm2/rnn/LSTM/block_input/biases/Adam\n",
      "\tre3/lstm2/rnn/LSTM/block_input/biases/Adam_1\n",
      "\tre3/lstm2/rnn/LSTM/block_input/weights/Adam\n",
      "\tre3/lstm2/rnn/LSTM/block_input/weights/Adam_1\n",
      "\tre3/lstm2/rnn/LSTM/forget_gate/biases/Adam\n",
      "\tre3/lstm2/rnn/LSTM/forget_gate/biases/Adam_1\n",
      "\tre3/lstm2/rnn/LSTM/forget_gate/weights/Adam\n",
      "\tre3/lstm2/rnn/LSTM/forget_gate/weights/Adam_1\n",
      "\tre3/lstm2/rnn/LSTM/input_gate/biases/Adam\n",
      "\tre3/lstm2/rnn/LSTM/input_gate/biases/Adam_1\n",
      "\tre3/lstm2/rnn/LSTM/input_gate/weights/Adam\n",
      "\tre3/lstm2/rnn/LSTM/input_gate/weights/Adam_1\n",
      "\tre3/lstm2/rnn/LSTM/output_gate/biases/Adam\n",
      "\tre3/lstm2/rnn/LSTM/output_gate/biases/Adam_1\n",
      "\tre3/lstm2/rnn/LSTM/output_gate/weights/Adam\n",
      "\tre3/lstm2/rnn/LSTM/output_gate/weights/Adam_1\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/Ilya/Kyrsach/Kyrsovaya/re3-tensorflow/checkpoints\\model.ckpt-0\n",
      "Restored C:/Users/Ilya/Kyrsach/Kyrsovaya/re3-tensorflow/checkpoints\\model.ckpt-0\n"
     ]
    }
   ],
   "source": [
    "tracker = re3_tracker.Re3Tracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['List',\n",
       " 'Person',\n",
       " 'Tuple',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'np']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(Person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Person.Person(1,1,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.color_id_and_cout_of_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': <Person.Person.Person at 0x22399b769e8>,\n",
       " '2': <Person.Person.Person at 0x22399b76a58>,\n",
       " '3': <Person.Person.Person at 0x22399b76eb8>,\n",
       " '4': <Person.Person.Person at 0x22399b76cf8>,\n",
       " '5': <Person.Person.Person at 0x22399b76d30>,\n",
       " '6': <Person.Person.Person at 0x22399b76e48>,\n",
       " '7': <Person.Person.Person at 0x22399b76080>,\n",
       " '8': <Person.Person.Person at 0x22399b76828>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(43, 272),\n",
       " (45, 291),\n",
       " (38, 332),\n",
       " (38, 337),\n",
       " (39, 324),\n",
       " (38, 327),\n",
       " (37, 327),\n",
       " (36, 330),\n",
       " (35, 332),\n",
       " (34, 333),\n",
       " (34, 339),\n",
       " (34, 342),\n",
       " (33, 348),\n",
       " (33, 355),\n",
       " (32, 362),\n",
       " (30, 367),\n",
       " (28, 371),\n",
       " (28, 375),\n",
       " (28, 377),\n",
       " (29, 382),\n",
       " (28, 383),\n",
       " (30, 383),\n",
       " (32, 384),\n",
       " (32, 384),\n",
       " (32, 381),\n",
       " (32, 381),\n",
       " (31, 385),\n",
       " (31, 386),\n",
       " (32, 388),\n",
       " (30, 390),\n",
       " (30, 393),\n",
       " (66, 427),\n",
       " (68, 426),\n",
       " (71, 422),\n",
       " (73, 418),\n",
       " (74, 416),\n",
       " (76, 415),\n",
       " (76, 415),\n",
       " (77, 415),\n",
       " (78, 414),\n",
       " (79, 411),\n",
       " (80, 407),\n",
       " (80, 402),\n",
       " (81, 395),\n",
       " (81, 389),\n",
       " (82, 383),\n",
       " (82, 376),\n",
       " (83, 371),\n",
       " (84, 368),\n",
       " (84, 366),\n",
       " (85, 364),\n",
       " (85, 362),\n",
       " (86, 360),\n",
       " (86, 358),\n",
       " (87, 356),\n",
       " (88, 354),\n",
       " (89, 351),\n",
       " (88, 349),\n",
       " (89, 346),\n",
       " (91, 340),\n",
       " (92, 335),\n",
       " (94, 331),\n",
       " (96, 324),\n",
       " (96, 318),\n",
       " (100, 311),\n",
       " (99, 307),\n",
       " (101, 304),\n",
       " (103, 299),\n",
       " (106, 300),\n",
       " (108, 298),\n",
       " (110, 296),\n",
       " (111, 293),\n",
       " (112, 291),\n",
       " (113, 289),\n",
       " (113, 288),\n",
       " (114, 285),\n",
       " (114, 281),\n",
       " (115, 277),\n",
       " (115, 270),\n",
       " (116, 266),\n",
       " (116, 260),\n",
       " (117, 255),\n",
       " (117, 249),\n",
       " (118, 245),\n",
       " (118, 243),\n",
       " (119, 240),\n",
       " (119, 238),\n",
       " (120, 237),\n",
       " (120, 235),\n",
       " (122, 232),\n",
       " (122, 231),\n",
       " (122, 229),\n",
       " (123, 226),\n",
       " (123, 224),\n",
       " (123, 220),\n",
       " (124, 216),\n",
       " (125, 211),\n",
       " (126, 207),\n",
       " (126, 201),\n",
       " (127, 195),\n",
       " (129, 190),\n",
       " (129, 185),\n",
       " (130, 182),\n",
       " (133, 180),\n",
       " (135, 178),\n",
       " (137, 177),\n",
       " (139, 175),\n",
       " (141, 174),\n",
       " (141, 172),\n",
       " (142, 170),\n",
       " (143, 169),\n",
       " (144, 166),\n",
       " (144, 163),\n",
       " (146, 159),\n",
       " (146, 155),\n",
       " (147, 149),\n",
       " (147, 145),\n",
       " (148, 140),\n",
       " (148, 137),\n",
       " (150, 132),\n",
       " (150, 128),\n",
       " (152, 127),\n",
       " (153, 125),\n",
       " (154, 123),\n",
       " (155, 122),\n",
       " (150, 89),\n",
       " (153, 89),\n",
       " (156, 117),\n",
       " (155, 89),\n",
       " (156, 88),\n",
       " (156, 87),\n",
       " (157, 85),\n",
       " (157, 83),\n",
       " (159, 80),\n",
       " (159, 77),\n",
       " (160, 73),\n",
       " (161, 70),\n",
       " (163, 67),\n",
       " (163, 65),\n",
       " (165, 65),\n",
       " (167, 65),\n",
       " (169, 65),\n",
       " (172, 64),\n",
       " (173, 64),\n",
       " (180, 67),\n",
       " (173, 63),\n",
       " (173, 64),\n",
       " (173, 64),\n",
       " (177, 63),\n",
       " (178, 61),\n",
       " (189, 58),\n",
       " (335, 41),\n",
       " (333, 41),\n",
       " (333, 44),\n",
       " (333, 48),\n",
       " (332, 53),\n",
       " (332, 56),\n",
       " (332, 58),\n",
       " (329, 60),\n",
       " (329, 61),\n",
       " (329, 61),\n",
       " (328, 62),\n",
       " (327, 62),\n",
       " (325, 62),\n",
       " (323, 62),\n",
       " (323, 62),\n",
       " (321, 62),\n",
       " (320, 65),\n",
       " (319, 67),\n",
       " (319, 68),\n",
       " (319, 74),\n",
       " (317, 81),\n",
       " (317, 86),\n",
       " (316, 91),\n",
       " (316, 96),\n",
       " (316, 100),\n",
       " (315, 102),\n",
       " (314, 104),\n",
       " (342, 108),\n",
       " (314, 107),\n",
       " (342, 111),\n",
       " (314, 110),\n",
       " (314, 113),\n",
       " (314, 115),\n",
       " (313, 118),\n",
       " (312, 122),\n",
       " (312, 129),\n",
       " (311, 134),\n",
       " (311, 139),\n",
       " (310, 144),\n",
       " (342, 150),\n",
       " (340, 153),\n",
       " (340, 156),\n",
       " (339, 157),\n",
       " (338, 158),\n",
       " (337, 160),\n",
       " (336, 161),\n",
       " (334, 162),\n",
       " (333, 164),\n",
       " (332, 165),\n",
       " (330, 167),\n",
       " (329, 169),\n",
       " (328, 171),\n",
       " (327, 174),\n",
       " (326, 181),\n",
       " (325, 188),\n",
       " (325, 194),\n",
       " (324, 200),\n",
       " (324, 203),\n",
       " (323, 207),\n",
       " (323, 209),\n",
       " (322, 211),\n",
       " (322, 213),\n",
       " (322, 214),\n",
       " (321, 216),\n",
       " (321, 218),\n",
       " (321, 219),\n",
       " (321, 221),\n",
       " (321, 222),\n",
       " (321, 224),\n",
       " (320, 225),\n",
       " (319, 227),\n",
       " (319, 233),\n",
       " (318, 240),\n",
       " (318, 246),\n",
       " (317, 251),\n",
       " (316, 255),\n",
       " (316, 258),\n",
       " (315, 261),\n",
       " (313, 263),\n",
       " (312, 265),\n",
       " (311, 267),\n",
       " (309, 268),\n",
       " (307, 270),\n",
       " (306, 271),\n",
       " (304, 273),\n",
       " (300, 276),\n",
       " (298, 278),\n",
       " (265, 275),\n",
       " (265, 281),\n",
       " (264, 287),\n",
       " (263, 295),\n",
       " (262, 301),\n",
       " (261, 305),\n",
       " (261, 308),\n",
       " (261, 311),\n",
       " (261, 313),\n",
       " (261, 315),\n",
       " (260, 317),\n",
       " (259, 319),\n",
       " (259, 321),\n",
       " (259, 322),\n",
       " (258, 323),\n",
       " (258, 325),\n",
       " (258, 327),\n",
       " (257, 328),\n",
       " (257, 330),\n",
       " (256, 333),\n",
       " (255, 341),\n",
       " (254, 349),\n",
       " (253, 360),\n",
       " (252, 363),\n",
       " (250, 369),\n",
       " (249, 370),\n",
       " (248, 372),\n",
       " (247, 374),\n",
       " (246, 376),\n",
       " (245, 377),\n",
       " (244, 379),\n",
       " (243, 380),\n",
       " (242, 383),\n",
       " (241, 387),\n",
       " (240, 390),\n",
       " (240, 394),\n",
       " (239, 399),\n",
       " (238, 405),\n",
       " (238, 412),\n",
       " (237, 418),\n",
       " (237, 424),\n",
       " (236, 426),\n",
       " (236, 428),\n",
       " (236, 430),\n",
       " (236, 432),\n",
       " (236, 434),\n",
       " (235, 436),\n",
       " (235, 437),\n",
       " (235, 439),\n",
       " (234, 440),\n",
       " (234, 442),\n",
       " (233, 443),\n",
       " (233, 445),\n",
       " (232, 446),\n",
       " (231, 448),\n",
       " (230, 450),\n",
       " (230, 451),\n",
       " (228, 453),\n",
       " (260, 466)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p['1'].get_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blue_down_line': [(230, 262), (544, 205)],\n",
       " 'intresting_zone': [(187, 29), (602, 29), (602, 360), (187, 360)],\n",
       " 'red_up_line': [(220, 80), (575, 158)]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
